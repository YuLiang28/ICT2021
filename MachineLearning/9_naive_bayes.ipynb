{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes 朴素贝叶斯\n",
    "\n",
    "朴素贝叶斯 = 朴素+贝叶斯  \n",
    "#### 什么是朴素？\n",
    "假设：特征与特征间相互独立 \n",
    "\n",
    "#### 贝叶斯公式\n",
    "\n",
    "$$P(C|W)=\\frac{P(W|C)P(C)}{P(W)}$$\n",
    "$W$为给文档的特征值（频数统计，预测文档提供），$C$为文档类别\n",
    "\n",
    "### 概率\n",
    "概率定义为一件事情发生的可能性  \n",
    "- 扔出一个硬币，结果头朝上  \n",
    "$P(X)$: 取值在$[0,1]$   \n",
    "当样本量较少，求得概率不符合实际  \n",
    "#### 联合概率、条件概率和相互独立\n",
    "- 联合概率：包含多个条件，且所有条件同时成立的概率\n",
    "  - 记作：$P(A,B)$\n",
    "- 条件概率：事件A在另外一个事件B已经发生的条件下发生的概率\n",
    "  - 记作：$P(A|B)$\n",
    "- 相互独立：$P(A,B)=P(A)P(B)$ <=> 事件A与事件B相互独立  \n",
    "\n",
    "#### 拉普拉斯平滑系数\n",
    "目的：防止计算出的分类概率为$0$\n",
    "\n",
    "$$P(F1|C)=\\frac{Ni+a}{N+am}$$\n",
    "\n",
    "$a$为指定的系数，一般为1，$m$为训练文档中统计出特征词的个数\n",
    "\n",
    "### 应用场景\n",
    "- 文本分类\n",
    "- 情感分析\n",
    "\n",
    "### API\n",
    "~~~python\n",
    "sklearn.naive_bayes.MultinomialNB(alpha=1.0)\n",
    "~~~\n",
    "- alpha：拉普拉斯平滑系数，默认值为1\n",
    "#### 优缺点\n",
    "- 优点：\n",
    "  - 稳定的分类效率\n",
    "  - 对缺失数据不敏感\n",
    "  - 算法简单，常用于文本分类\n",
    "  - 分类准确度高，速度快\n",
    "- 缺点：\n",
    "  - 基于样本属性独立性的假设，如果特征属性有关联时效果不好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fetch dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news = fetch_20newsgroups(subset=\"all\")\n",
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14134"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(news.data, news.target)\n",
    "len(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "\n",
    "#   tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "transfer = TfidfVectorizer()\n",
    "x_train = transfer.fit_transform(x_train)\n",
    "x_test = transfer.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0062}\n",
      "0.9075288297244075\n"
     ]
    }
   ],
   "source": [
    "# naive bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "bayes = MultinomialNB()\n",
    "# estimator.fit(x_train, y_train)\n",
    "\n",
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {  \n",
    "            \"alpha\":[ x/100000 for x in range(620,630)] // 0.0062 - 0.0063\n",
    "        }\n",
    "\n",
    "estimator = GridSearchCV(bayes,params,cv=7)\n",
    "estimator.fit(x_train,y_train)\n",
    "print(estimator.best_params_)\n",
    "print(estimator.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0062,\n",
       " 0.00621,\n",
       " 0.00622,\n",
       " 0.00623,\n",
       " 0.00624,\n",
       " 0.00625,\n",
       " 0.00626,\n",
       " 0.00627,\n",
       " 0.00628,\n",
       " 0.00629]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ x/100000 for x in range(620,630,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predict=[10 17  3 ...  7  7  3]\n",
      "y_test == y_predict:\n",
      "[ True  True  True ...  True  True  True]\n",
      "y_predict_proba=\n",
      "[[3.16027112e-12 1.96630206e-12 2.41688941e-12 ... 2.66223491e-12\n",
      "  9.79786623e-12 7.84250749e-12]\n",
      " [8.62548332e-08 2.74693665e-11 1.51935656e-12 ... 9.99999720e-01\n",
      "  5.14232885e-08 1.93974445e-08]\n",
      " [6.19775393e-10 1.49465937e-07 2.61779324e-04 ... 9.61709228e-10\n",
      "  5.18669936e-09 1.80494377e-09]\n",
      " ...\n",
      " [1.37573788e-11 3.41738760e-11 9.76740852e-11 ... 1.89792413e-11\n",
      "  1.93602783e-11 1.22295400e-11]\n",
      " [3.03595279e-09 8.38162594e-09 1.20326573e-08 ... 2.14108429e-09\n",
      "  3.72086243e-09 1.72861815e-08]\n",
      " [6.60769988e-07 1.09635675e-05 1.65287266e-04 ... 3.24392255e-07\n",
      "  2.26919262e-06 5.59362547e-07]]\n",
      "score:0.9182937181663837\n"
     ]
    }
   ],
   "source": [
    "# model evaluate\n",
    "# 1. 直接比对真实值和预测值  \n",
    "y_predict = estimator.predict(x_test)  \n",
    "print(f\"y_predict={y_predict}\")\n",
    "print(f\"y_test == y_predict:\\n{y_test == y_predict}\")\n",
    "\n",
    "y_predict_proba = estimator.predict_proba(x_test)\n",
    "print(f\"y_predict_proba=\\n{y_predict_proba}\")\n",
    "\n",
    "# 2. 计算准确率  \n",
    "score = estimator.score(x_test,y_test)\n",
    "print(f\"score:{score}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "455d156c2443f23ffeb7a3cb87ade32cade494afff05783b4faa4f6a104c976b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
