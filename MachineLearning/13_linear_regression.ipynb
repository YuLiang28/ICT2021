{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性回归 Linear Regression\n",
    "\n",
    "#### 应用场景\n",
    "- 房价预测\n",
    "- 销售额度预测\n",
    "- 贷款额度预测\n",
    "#### 原理\n",
    "线性回归（Linear Regression）是利用回归方程（函数）对一个或多个自变量（特征值）和因变量（目标值）之间关系进行建模的一种分析方程。\n",
    "\n",
    "- 单变量回归：只有一个自变量\n",
    "- 多元回归：多个自变量\n",
    "通用公式  \n",
    "$$h(w)=w_1x_1+w_2x_2+w_3x_3\\dots+b=w^Tx+b$$\n",
    "其中$w,x$可以理解为矩阵：$w=\\begin{pmatrix}b\\\\w_1\\\\w_2\\end{pmatrix},x=\\begin{pmatrix}1\\\\x_1\\\\x_2\\end{pmatrix}$,$b$为偏置  \n",
    "其实就是$y=kx+b$\n",
    "\n",
    "- 找到特征值与目标值间函数关系，这个关系可以理解为线性模型\n",
    "广义的线性模型：\n",
    "- 线性关系：单特征与目标值的关系呈直线关系，两个特征与目标值呈现平面关系\n",
    "- 非线性关系：不能用一个直线或平面来拟合\n",
    "- ***线性关系一定是线性模型***\n",
    "- ***线性模型不一定是线性关系***\n",
    "\n",
    "我们应该怎样从一大堆数据里求出回归方程呢？ 假定输入数据存放在矩阵 $x$ 中，而回归系数存放在向量 $w$ 中。那么对于给定的数据 $X1$，预测结果将会通过 $Y = X1^T w$给出。现在的问题是，手里有一些 $X$ 和对应的 $y$，怎样才能找到 $w$ 呢？一个常用的方法就是找出使误差最小的 $w$ 。这里的误差是指预测 $y$ 值和真实 $y$ 值之间的差值，使用该误差的简单累加将使得正差值和负差值相互抵消，所以我们采用平方误差（实际上就是我们通常所说的最小二乘法）。\n",
    "\n",
    "### 损失和优化\n",
    "目标:求模型参数  \n",
    "模型参数能够使得预测准确  \n",
    "\n",
    "例如，假设某房屋价格与环境参数存在如下关系：\n",
    "- $真实房价=0.02*中心区域距离+0.04*城市一氧化氮浓度\\dots$  \n",
    "\n",
    "那么现在我们随意指定（猜测）一个关系\n",
    "\n",
    "- $预测房价=0.25*中心区域距离+0.14*城市一氧化氮浓度\\dots$\n",
    "\n",
    "真实值和预测结果是存在一定误差的，衡量误差的函数便是：损失函数\n",
    "\n",
    "损失函数:\n",
    "一般是最小二乘法（又称最小平方法）一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。\n",
    "\n",
    "如何去求模型的 $w$ ,使得损失最小？  \n",
    "线性回归常用优化算法：\n",
    "- 正规方程 Normal Equation （较少使用）\n",
    "  - 可以比喻成一个天才\n",
    "  - 当特征过多过复杂时，求解速度太慢并且得不到结果\n",
    "  - 小数据场景有优势\n",
    "  - 直接求解$w$，$X$为特征值矩阵，$y$为目标值矩阵，直接求的最好结果\n",
    "$$w = (X^TX)^{-1}X^Ty$$\n",
    "\n",
    "\n",
    "\n",
    "- 梯度下降 Gradient Descent（较多使用）\n",
    "  - 可以比喻成是勤奋努力的普通人\n",
    "  - 不断地改进、试错直到成功\n",
    "  - $\\alpha$ 为学习速率，需要手动指定，$\\alpha$右边整体表示函数下降的方向\n",
    "  - 面对规模十分庞大的数据集，能找到较好的结果\n",
    "$$\n",
    "w1 := w1 - \\alpha\\frac{{\\partial}cost(w0+w1x1)}{{\\partial}w1}\n",
    "$$\n",
    "$$\n",
    "w0 := w0 - \\alpha\\frac{{\\partial}cost(w0+w1x1)}{{\\partial}w1}\n",
    "$$\n",
    "\n",
    "### API\n",
    "~~~python\n",
    "sklearn.linear_model.LinearRegression\n",
    "~~~\n",
    "- 通过正规方程优化\n",
    "- fit_intercept: 是否计算偏置\n",
    "- LinearRegression.coef_: 回归系数\n",
    "- LinearRegression.intercept_: 偏置\n",
    "\n",
    "~~~python\n",
    "sklearn.linear_model.SGDRegressor\n",
    "~~~\n",
    "- SGDRegressor 类实现了随机梯度下降学习，支持不同的loss函数和正则化惩罚项来拟合线性回归模型\n",
    "- loss:损失类型\n",
    "  - squared_error：普通最小二乘法\n",
    "  - huber\n",
    "  - epsilon_insensitive\n",
    "  - squared_epsilon_insensitive\n",
    "- fit_intercept: 是否计算偏置\n",
    "- learning_rate: 学习率的算法，eta是学习率\n",
    "  - ‘constant’: eta = eta0\n",
    "  - ‘optimal’: eta = 1.0 / (alpha * (t + t0))\n",
    "  - ‘invscaling’: eta = eta0 / pow(t, power_t) 逐步减小学习率\n",
    "    - power_t：默认是0.25\n",
    "  - ‘adaptive’: eta = eta0\n",
    "- SGDRegressor.coef_: 回归系数\n",
    "- SGDRegressor.intercept_: 偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boston house price\n",
    "# length: 506\n",
    "# CRIM - 城镇人均犯罪率                                                              ------【城镇人均犯罪率】\n",
    "# ZN - 占地面积超过25,000平方英尺的住宅用地比例。               ------【住宅用地所占比例】\n",
    "# INDUS - 每个城镇非零售业务的比例。                                      ------【城镇中非商业用地占比例】\n",
    "# CHAS - Charles River虚拟变量（如果是河道，则为1;否则为0  ------【查尔斯河虚拟变量，用于回归分析】\n",
    "# NOX - 一氧化氮浓度（每千万份）                                             ------【环保指标】\n",
    "# RM - 每间住宅的平均房间数                                                      ------【每栋住宅房间数】\n",
    "# AGE - 1940年以前建造的自住单位比例                                     ------【1940年以前建造的自住单位比例 】\n",
    "# DIS -波士顿的五个就业中心加权距离                                        ------【与波士顿的五个就业中心加权距离】\n",
    "# RAD - 径向高速公路的可达性指数                                             ------【距离高速公路的便利指数】\n",
    "# TAX - 每10,000美元的全额物业税率                                          ------【每一万美元的不动产税率】\n",
    "# PTRATIO - 城镇的学生与教师比例                                             ------【城镇中教师学生比例】\n",
    "# B - 1000（Bk - 0.63）^ 2其中Bk是城镇黑人的比例                   ------【城镇中黑人比例】\n",
    "# LSTAT - 人口状况下降％                                                            ------【房东属于低等收入阶层比例】\n",
    "# MEDV - 自有住房的中位数报价, 单位1000美元                         ------【自住房屋房价中位数】\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\source\\tools\\miniconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取数据集\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "boston.data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.80028e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        2.27610e+02, 1.21400e+01],\n",
       "       [2.14090e-01, 2.20000e+01, 5.86000e+00, ..., 1.91000e+01,\n",
       "        3.77070e+02, 3.59000e+00],\n",
       "       [2.99160e-01, 2.00000e+01, 6.96000e+00, ..., 1.86000e+01,\n",
       "        3.88650e+02, 1.30000e+01],\n",
       "       ...,\n",
       "       [4.41700e-02, 7.00000e+01, 2.24000e+00, ..., 1.48000e+01,\n",
       "        3.90860e+02, 6.07000e+00],\n",
       "       [5.90050e-01, 0.00000e+00, 2.18900e+01, ..., 2.12000e+01,\n",
       "        3.85760e+02, 1.11200e+01],\n",
       "       [1.11081e+01, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        3.96900e+02, 3.47700e+01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(boston.data,boston.target,random_state=22)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20918739, -0.52054534,  1.24477931, ..., -1.72807526,\n",
       "        -1.35897227, -0.08447646],\n",
       "       [-0.43088174,  0.3974553 , -0.7606374 , ...,  0.30003249,\n",
       "         0.24261973, -1.25661718],\n",
       "       [-0.41899191,  0.3140007 , -0.59985326, ...,  0.0695657 ,\n",
       "         0.36670935,  0.03342307],\n",
       "       ...,\n",
       "       [-0.45463067,  2.4003658 , -1.28976339, ..., -1.6819819 ,\n",
       "         0.3903914 , -0.91662782],\n",
       "       [-0.37833557, -0.52054534,  1.582426  , ...,  1.26799301,\n",
       "         0.33574053, -0.22431079],\n",
       "       [ 1.09172307, -0.52054534,  1.02845156, ...,  0.80705943,\n",
       "         0.45511517,  3.0179264 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "x_train = std.fit_transform(x_train)\n",
    "x_test = std.transform(x_test)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line coef_: [-0.64817766  1.14673408 -0.05949444  0.74216553 -1.95515269  2.70902585\n",
      " -0.07737374 -3.29889391  2.50267196 -1.85679269 -1.75044624  0.87341624\n",
      " -3.91336869]\n",
      "line intercept_: 22.62137203166228\n"
     ]
    }
   ],
   "source": [
    "# 预估器\n",
    "\n",
    "# 使用正规方程优化\n",
    "from sklearn.linear_model import LinearRegression\n",
    "line = LinearRegression()\n",
    "line.fit(x_train, y_train)\n",
    "print(\"line coef_:\",line.coef_)\n",
    "print(\"line intercept_:\",line.intercept_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd coef_: [-0.53193036  0.94238144 -0.46270788  0.75302461 -1.70467432  2.80901494\n",
      " -0.18054647 -3.08906517  1.62059772 -0.93274257 -1.71390531  0.90184191\n",
      " -3.90576195]\n",
      "sgd intercept_: [22.60308145]\n"
     ]
    }
   ],
   "source": [
    "# 使用梯度下降优化\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd = SGDRegressor()\n",
    "sgd.fit(x_train, y_train)\n",
    "print(\"sgd coef_:\",sgd.coef_)\n",
    "print(\"sgd intercept_:\",sgd.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_estimator_ SGDRegressor()\n",
      "best_score_ 0.6908118957589295\n",
      "sgdGS coef_: [-0.45453792  0.7900262  -0.50798626  0.82352197 -1.46464809  2.94375814\n",
      " -0.17221067 -2.80360658  1.32451916 -0.75453759 -1.6912992   0.88494938\n",
      " -3.93564441]\n",
      "sgdGS intercept_: [22.60340085]\n"
     ]
    }
   ],
   "source": [
    "# 网格搜索对梯度下降调参\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "estimator = SGDRegressor()\n",
    "params = {\n",
    "    \"penalty\":[\"l2\",\"l1\",\"elasticnet\"],\n",
    "    \"learning_rate\":[\"constant\",\"optimal\",\"invscaling\",\"adaptive\"],\n",
    "    \"eta0\":[0.1,0.01,0.005,0.001]\n",
    "}\n",
    "grid = GridSearchCV(estimator,params,n_jobs=-1)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"best_estimator_\",grid.best_estimator_)\n",
    "print(\"best_score_\",grid.best_score_)\n",
    "\n",
    "\n",
    "sgdGS = SGDRegressor(eta0=grid.best_params_[\"eta0\"],learning_rate=grid.best_params_[\"learning_rate\"],penalty=grid.best_params_[\"penalty\"])\n",
    "sgdGS.fit(x_train, y_train)\n",
    "\n",
    "print(\"sgdGS coef_:\",sgdGS.coef_)\n",
    "print(\"sgdGS intercept_:\",sgdGS.intercept_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "455d156c2443f23ffeb7a3cb87ade32cade494afff05783b4faa4f6a104c976b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
