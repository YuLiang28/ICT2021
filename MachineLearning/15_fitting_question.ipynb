{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过拟合（Overfitting）和欠拟合（Underfitting）\n",
    "- 欠拟合\n",
    "  - 模型不能在训练集上获得足够低的误差\n",
    "  - 模型过于简单，模型容量（capacity）低\n",
    "- 过拟合\n",
    "  - 在训练误差和测试误差之间差距太大\n",
    "  - 训练集上表现得很好，测试集上不好\n",
    "  - 模型过于复杂，模型容量（capacity）高\n",
    "\n",
    "\n",
    "![过拟合和欠拟合1](src/over_under_fitting_1.png)\n",
    "![过拟合和欠拟合2](src/over_under_fitting_2.png)\n",
    "![过拟合和欠拟合3](src/over_under_fitting_3.png)\n",
    "\n",
    "\n",
    "#### 解决方案\n",
    "- 欠拟合\n",
    "  - 原因：学习到的特征过少\n",
    "  - 解决方法：增加数据特征数量\n",
    "- 过拟合\n",
    "  - 原因：原始特征过多，存在一些嘈杂特征，模型过于复杂是因为模型尝试去兼顾各个测试数据点\n",
    "  - 解决方法：正则化\n",
    "\n",
    "#### 正则化 regularization\n",
    "正则化的目的是限制参数过多或者过大，避免模型更加复杂。  \n",
    "\n",
    "\n",
    "- L2正则化（更常用）\n",
    "  - 作用：可以使得其中一些W变小，接近于0，削弱某个特征的影响\n",
    "  - 优点：越小的参数说明模型越简单，越简单的模型越不容易产生过拟合现象\n",
    "  - Ridge回归-岭回归\n",
    "$$J(w)=MSE_{train}+\\lambda\\sum^{n}_{j=1}w_j^2$$\n",
    "尽可能地让损失函数变小，权重系数也会变小，其中$\\lambda$是提前挑选好的值，控制我们偏好小范数权重的程度，当$\\lambda=0$时我们没有任何偏好\n",
    "- L1正则化\n",
    "  - 可以使得其中一些W的值直接为0，删除这个特征的影响\n",
    "  - LASSO回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
