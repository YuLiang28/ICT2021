{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树 Decision Tree\n",
    "决策树（Decision Tree）算法是一种基本的分类与回归方法，是最经常使用的数据挖掘算法之一。  \n",
    "\n",
    "决策树模型呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程。它可以认为是 if-then 规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布。  \n",
    "\n",
    "决策树学习通常包括 3 个步骤: \n",
    "1. 特征选择\n",
    "2. 决策树的生成\n",
    "3. 决策树的修剪\n",
    "\n",
    "如何高效的进行决策？\n",
    "- 特征的先后顺序\n",
    "\n",
    "#### 信息论基础\n",
    "- 信息（information）：\n",
    "  - 凡是在一种情况下能减少不确定性的任何事物都叫信息。\n",
    "  - 信息是物质存在的一种方式、形态或运动形态，也是事物的一种普遍属性，一般指数据、消息中所包含的意义，***可以使消息中所描述事件中的不定性减少***。 \n",
    "\n",
    "\n",
    "- 信息的衡量 - 信息量 - 信息熵\n",
    "\n",
    "- 熵（entropy）: \n",
    "  - 熵指的是体系的混乱的程度。\n",
    "  - 在不同的学科中也有引申出的更为具体的定义，是各领域十分重要的参量。  \n",
    "\n",
    "\n",
    "- 信息论（information theory）中的熵（香农熵）: \n",
    "  - 是一种信息的度量方式，表示信息的混乱程度。\n",
    "  - 也就是说: 信息越有序，信息熵越低。\n",
    "  - 例如: 火柴有序放在火柴盒里，熵值很低，相反，熵值很高。  \n",
    "  - 公式如下:\n",
    "$$H = \\sum_{k=1}^{n}p_klog_2p_k$$\n",
    "\n",
    "- 信息增益（information gain）: \n",
    "  - 得知特征X的信息的不确定性减少的程度使得类Y的信息熵减少的程度\n",
    "  - 在划分数据集前后信息发生的变化称为信息增益  \n",
    "\n",
    "#### 决策树划分依据\n",
    "- 信息增益：\n",
    "  - 特征A对训练数据集D的信息增益g(D,A),定义为集合D的信息熵H(D)与特征A给定条件下D的信息条件熵H(D|A)之差，即公式为：\n",
    "$$信息增益 = 信息熵 - 条件熵$$\n",
    "$$g(D,A)=H(D)-H(D|A)$$\n",
    "- ID3:\n",
    "  - 信息增益 最大的准则\n",
    "- C4.5:\n",
    "  - 信息增益比 最大的准则\n",
    "- CART:\n",
    "  - 分类树：基尼系数 最小的准则 在sklearn中可以选择划分的默认原则\n",
    "  - 优势：划分更加细致\n",
    "### API\n",
    "~~~python\n",
    "# 决策树分类器\n",
    "sklearn.tree.DecisionTreeClassifier\n",
    "~~~\n",
    "- criterion：默认是基尼系数(gini)，也可以选择信息增益的熵(entropy)\n",
    "- max_depth: 树的深度，太深容易过拟合\n",
    "- random_state: 随机数种子\n",
    "\n",
    "### 总结\n",
    "- 优点\n",
    "  - 简单易理解，树可以可视化\n",
    "- 缺点\n",
    "  - 容易过拟合\n",
    "- 改进\n",
    "  - 减枝cart算法\n",
    "  - 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(estimator):\n",
    "    # model evaluate\n",
    "    # 1. 直接比对真实值和预测值  \n",
    "    y_predict = estimator.predict(x_test)  \n",
    "    print(f\"y_predict={y_predict}\")\n",
    "    print(f\"y_test == y_predict:\\n{y_test == y_predict}\")\n",
    "\n",
    "    y_predict_proba = estimator.predict_proba(x_test)\n",
    "    print(f\"y_predict_proba=\\n{y_predict_proba}\")\n",
    "\n",
    "    # 2. 计算准确率  \n",
    "    score = estimator.score(x_test,y_test)\n",
    "    print(f\"score:{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(iris.data,iris.target,random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predict=[0 0 0 2 1 1 2 2 1 2 0 2 1 1 0 1 0 0 0 1 2 0 0 0 2 2 2 2 0 1 2 1 2 2 2 2 1\n",
      " 2]\n",
      "y_test == y_predict:\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "y_predict_proba=\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "score:0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "tree.fit(x_train, y_train)\n",
    "print_score(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy'}\n",
      "y_predict=[0 0 0 2 1 1 2 2 1 2 0 2 1 1 0 1 0 0 0 1 2 0 0 0 2 2 2 2 0 1 2 1 2 2 2 2 1\n",
      " 2]\n",
      "y_test == y_predict:\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "y_predict_proba=\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "score:0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "estimator = DecisionTreeClassifier()\n",
    "params = {\n",
    "    \"criterion\":[\"gini\",\"entropy\"],\n",
    "}\n",
    "clf = GridSearchCV(estimator,params,cv=7)\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print_score(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化\n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(tree,out_file=\"./out/iris_tree.dot\",feature_names=iris.feature_names)\n",
    "# 网站查看\n",
    "# http://www.webgraphviz.com/?tab=map"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "455d156c2443f23ffeb7a3cb87ade32cade494afff05783b4faa4f6a104c976b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
